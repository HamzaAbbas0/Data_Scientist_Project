{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6906eb0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-10-25 06:00:00', '2023-10-25 06:05:00',\n",
      "               '2023-10-25 06:10:00', '2023-10-25 06:15:00',\n",
      "               '2023-10-25 06:20:00', '2023-10-25 06:25:00',\n",
      "               '2023-10-25 06:30:00', '2023-10-25 06:35:00',\n",
      "               '2023-10-25 06:40:00', '2023-10-25 06:45:00',\n",
      "               ...\n",
      "               '2023-10-30 05:10:00', '2023-10-30 05:15:00',\n",
      "               '2023-10-30 05:20:00', '2023-10-30 05:25:00',\n",
      "               '2023-10-30 05:30:00', '2023-10-30 05:35:00',\n",
      "               '2023-10-30 05:40:00', '2023-10-30 05:45:00',\n",
      "               '2023-10-30 05:50:00', '2023-10-30 05:55:00'],\n",
      "              dtype='datetime64[ns]', name='Time', length=31680, freq=None)\n",
      "[[[0.00000000e+00 3.13244862e-01 2.82333568e-01 ... 8.22903513e-03\n",
      "   1.70632351e-03 0.00000000e+00]]\n",
      "\n",
      " [[2.16000000e+04 2.67198642e-01 2.31332559e-01 ... 0.00000000e+00\n",
      "   1.78810497e-04 1.00000000e+00]]\n",
      "\n",
      " [[1.72800000e+04 2.81023100e-01 2.46594088e-01 ... 7.36231309e-05\n",
      "   1.52660344e-05 1.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.59190000e+04 2.29017058e-01 1.48913969e-01 ... 0.00000000e+00\n",
      "   4.32446188e-03 2.00000000e+00]]\n",
      "\n",
      " [[2.73590000e+04 1.61949118e-01 7.48883079e-02 ... 0.00000000e+00\n",
      "   3.26911321e-02 2.00000000e+00]]\n",
      "\n",
      " [[1.43990000e+04 3.08619297e-01 2.37318756e-01 ... 6.30753593e-03\n",
      "   1.30789293e-03 1.00000000e+00]]]\n",
      "[0.26719864 0.2810231  0.08879    ... 0.16194912 0.3086193  0.29440757]\n",
      "Reshaped X:  (31679, 1, 9)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py39/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0715\n",
      "Epoch 2/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0202\n",
      "Epoch 3/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0194\n",
      "Epoch 4/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0192\n",
      "Epoch 5/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0193\n",
      "Epoch 6/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0192\n",
      "Epoch 7/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0193\n",
      "Epoch 8/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0192\n",
      "Epoch 9/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0187\n",
      "Epoch 10/10\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0193\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048  \n",
      "Test Loss: 0.004838042892515659\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Bussiness_facility/combined_data.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "data.set_index('Time', inplace=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "data[['BG', 'CGM', 'CHO', 'insulin', 'LBGI', 'HBGI', 'Risk']] = scaler.fit_transform(data[['BG', 'CGM', 'CHO', 'insulin', 'LBGI', 'HBGI', 'Risk']])\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "data['Patient'] = encoder.fit_transform(data['Patient'])\n",
    "\n",
    "print(data.index)\n",
    "\n",
    "# Ensure the index is sorted in chronological order\n",
    "if not data.index.is_monotonic_increasing:\n",
    "    data = data.sort_index()\n",
    "\n",
    "# Sequence generation\n",
    "def generate_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq_data = data.iloc[i:i+seq_length]\n",
    "#         print(\"seq_data: \", seq_data)\n",
    "        seq_target = data.iloc[i+seq_length]['BG']  # Assuming predicting BG\n",
    "#         print(\"seq_target: \", seq_target)\n",
    "        sequences.append(seq_data.values)\n",
    "#         print(\"sequences: \", sequences)\n",
    "        targets.append(seq_target)\n",
    "#         print(\"target: \", targets)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 1\n",
    "X, y = generate_sequences(data, sequence_length)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# Reshape X to 3D array (samples, timesteps, features)\n",
    "X = X.reshape(X.shape[0], sequence_length, -1)\n",
    "print(\"Reshaped X: \", X.shape)\n",
    "\n",
    "# Ensure that the number of features matches the input shape expected by the LSTM layer\n",
    "num_features = X.shape[2]\n",
    "\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(sequence_length, num_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Model training\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "# For simplicity, let's use the last portion of the data as the test set\n",
    "test_data = data.iloc[-100:]\n",
    "X_test, y_test = generate_sequences(test_data, sequence_length)\n",
    "X_test = X_test.reshape(X_test.shape[0], sequence_length, -1)\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dacd6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-10-25 06:00:00')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "107bcfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1 days 00:00:00')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "990fe0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-15 00:00:00')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_date = pd.Timestamp('2024-01-15')\n",
    "specific_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85284948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0        BG       CGM  CHO   insulin      LBGI      HBGI  \\\n",
      "Time                                                                            \n",
      "2023-10-29       19800  0.244653  0.203085  0.0  0.005167  0.001884  0.000000   \n",
      "2023-10-29       16920  0.185279  0.135784  0.0  0.003795  0.018660  0.000000   \n",
      "2023-10-29       21240  0.127987  0.073126  0.0  0.002902  0.065764  0.000000   \n",
      "2023-10-29       12600  0.204869  0.158231  0.0  0.003788  0.010647  0.000000   \n",
      "2023-10-29       18360  0.181630  0.134075  0.0  0.003051  0.020500  0.000000   \n",
      "...                ...       ...       ...  ...       ...       ...       ...   \n",
      "2023-10-30        4248  0.313289  0.288386  0.0  0.001869  0.000000  0.008248   \n",
      "2023-10-30       20088  0.169969  0.131010  0.0  0.005167  0.027227  0.000000   \n",
      "2023-10-30       11448  0.207320  0.172888  0.0  0.003391  0.009842  0.000000   \n",
      "2023-10-30        2808  0.199927  0.163822  0.0  0.000985  0.012395  0.000000   \n",
      "2023-10-30        7128  0.229021  0.197784  0.0  0.001274  0.004324  0.000000   \n",
      "\n",
      "                Risk  Patient  \n",
      "Time                           \n",
      "2023-10-29  0.001884        1  \n",
      "2023-10-29  0.018660        1  \n",
      "2023-10-29  0.065764        1  \n",
      "2023-10-29  0.010647        1  \n",
      "2023-10-29  0.020500        1  \n",
      "...              ...      ...  \n",
      "2023-10-30  0.001710        0  \n",
      "2023-10-30  0.027227        1  \n",
      "2023-10-30  0.009842        1  \n",
      "2023-10-30  0.012395        0  \n",
      "2023-10-30  0.004324        0  \n",
      "\n",
      "[6358 rows x 9 columns]\n",
      "Shape of X_inference: (1, 1, 57222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3429388/652238072.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_data[['BG', 'CGM', 'CHO', 'insulin', 'LBGI', 'HBGI', 'Risk']] = scaler.transform(input_data[['BG', 'CGM', 'CHO', 'insulin', 'LBGI', 'HBGI', 'Risk']])\n",
      "/tmp/ipykernel_3429388/652238072.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_data['Patient'] = encoder.fit_transform(input_data['Patient'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 57222 and 9 for '{{node sequential_12_1/lstm_12_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_12_1/lstm_12_1/strided_slice_1, sequential_12_1/lstm_12_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [1,57222], [9,200].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(1, 57222), dtype=float32)\n  • states=('tf.Tensor(shape=(1, 50), dtype=float32)', 'tf.Tensor(shape=(1, 50), dtype=float32)')\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_inference:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_inference\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m predicted_bg \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_inference\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Optionally inverse transform the prediction\u001b[39;00m\n\u001b[1;32m     28\u001b[0m predicted_bg \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(predicted_bg)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 57222 and 9 for '{{node sequential_12_1/lstm_12_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_12_1/lstm_12_1/strided_slice_1, sequential_12_1/lstm_12_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [1,57222], [9,200].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(1, 57222), dtype=float32)\n  • states=('tf.Tensor(shape=(1, 50), dtype=float32)', 'tf.Tensor(shape=(1, 50), dtype=float32)')\n  • training=False"
     ]
    }
   ],
   "source": [
    "specific_date = pd.Timestamp('2023-10-30')\n",
    "\n",
    "# Check if the specific date exists in the dataset\n",
    "if specific_date in data.index:\n",
    "    # Extract data for the specific date\n",
    "    input_data = data.loc[specific_date - pd.Timedelta(days=sequence_length):specific_date]\n",
    "    print(input_data)\n",
    "\n",
    "    # Check if there is enough data for inference\n",
    "    if len(input_data) >= sequence_length:\n",
    "        try:\n",
    "            # Preprocess input data\n",
    "            input_data[['BG', 'CGM', 'CHO', 'insulin', 'LBGI', 'HBGI', 'Risk']] = scaler.transform(input_data[['BG', 'CGM', 'CHO', 'insulin', 'LBGI', 'HBGI', 'Risk']])\n",
    "            input_data['Patient'] = encoder.fit_transform(input_data['Patient'])\n",
    "        except KeyError as e:\n",
    "            print(\"Error:\", e)\n",
    "            print(\"Skipping preprocessing for Patient column.\")\n",
    "\n",
    "        # Generate sequence for input data\n",
    "        X_inference = input_data.values.reshape(1, sequence_length, -1)\n",
    "        print(\"Shape of X_inference:\", X_inference.shape)\n",
    "\n",
    "\n",
    "        # Make predictions\n",
    "        predicted_bg = model.predict(X_inference)\n",
    "\n",
    "        # Optionally inverse transform the prediction\n",
    "        predicted_bg = scaler.inverse_transform(predicted_bg)\n",
    "\n",
    "        print(\"Predicted BG for {}: {}\".format(specific_date, predicted_bg))\n",
    "    else:\n",
    "        print(\"Not enough data available for inference.\")\n",
    "else:\n",
    "    print(\"Selected date does not exist in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d091e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
